{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Media and Sentiment Mining - Programming Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawl review data from Yelp website for train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries for web crawler\n",
    "import urllib\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define restaurant names and URLs\n",
    "train_urls = {\n",
    "    \"no-signboard-seafood-restaurant\": \"https://www.yelp.com/biz/no-signboard-seafood-restaurant-singapore-4\", \n",
    "    \"40-hands\": \"https://www.yelp.com/biz/40-hands-singapore\",\n",
    "    \"jumbo-seafood\": \"https://www.yelp.com/biz/jumbo-seafood-singapore-2\",\n",
    "    \"keisuke-tonkotsu-king\": \"https://www.yelp.com/biz/keisuke-tonkotsu-king-singapore\",\n",
    "    \"tolidos-espresso-nook\": \"https://www.yelp.com/biz/tolidos-espresso-nook-singapore\",\n",
    "    \"liao-fan-hong-kong-soya-sauce-chicken-rice-and-noodle\": \"https://www.yelp.com/biz/liao-fan-hong-kong-soya-sauce-chicken-rice-and-noodle-singapore\",\n",
    "    \"din-tai-fung\": \"https://www.yelp.com/biz/din-tai-fung-singapore-16\",\n",
    "    \"santouka\": \"https://www.yelp.com/biz/santouka-singapore\",\n",
    "    \"sungei-road-laksa\": \"https://www.yelp.com/biz/sungei-road-laksa-singapore-2\",\n",
    "    \"long-beach-seafood\": \"https://www.yelp.com/biz/long-beach-seafood-singapore\",\n",
    "    \"komala-vilas-restaurant\": \"https://www.yelp.com/biz/komala-vilas-restaurant-singapore\",\n",
    "    \"burnt-ends\": \"https://www.yelp.com/biz/burnt-ends-singapore\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define html parser help function\n",
    "def make_soup(url):\n",
    "    thepage = urllib.request.urlopen(url)\n",
    "    soupdata = BeautifulSoup(thepage, \"html.parser\")\n",
    "    return soupdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = []\n",
    "ratings = []\n",
    "names = []\n",
    "\n",
    "for name, url in train_urls.items():\n",
    "    soup = make_soup(url)\n",
    "\n",
    "    for link in soup.find_all(\"div\", {\"class\": \"review-content\"}):\n",
    "        reviews.append(link.find('p').text)\n",
    "        ratings.append(link.find_all('img')[0].attrs['alt'])\n",
    "        names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, url in train_urls.items():\n",
    "    string1 = url\n",
    "    string2 = '?start='\n",
    "    string3 = str(20)\n",
    "    longstring = string1 + string2 + string3\n",
    "\n",
    "    soup = make_soup(longstring)\n",
    "\n",
    "    for link in soup.find_all(\"div\", {\"class\": \"review-content\"}):\n",
    "        reviews.append(link.find('p').text)\n",
    "        ratings.append(link.find_all('img')[0].attrs['alt'])\n",
    "        names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, url in train_urls.items():\n",
    "    string1 = url\n",
    "    string2 = '?start='\n",
    "    string3 = str(40)\n",
    "    longstring = string1 + string2 + string3\n",
    "\n",
    "    soup = make_soup(longstring)\n",
    "\n",
    "    for link in soup.find_all(\"div\", {\"class\": \"review-content\"}):\n",
    "        reviews.append(link.find('p').text)\n",
    "        ratings.append(link.find_all('img')[0].attrs['alt'])\n",
    "        names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(624, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.DataFrame({'Review': reviews, 'Rating': ratings, 'Restaurant': names})\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Restaurant</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40-hands</th>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>burnt-ends</th>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>din-tai-fung</th>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jumbo-seafood</th>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keisuke-tonkotsu-king</th>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>komala-vilas-restaurant</th>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liao-fan-hong-kong-soya-sauce-chicken-rice-and-noodle</th>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long-beach-seafood</th>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no-signboard-seafood-restaurant</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>santouka</th>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sungei-road-laksa</th>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tolidos-espresso-nook</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Review  Rating\n",
       "Restaurant                                                        \n",
       "40-hands                                                51      51\n",
       "burnt-ends                                              58      58\n",
       "din-tai-fung                                            49      49\n",
       "jumbo-seafood                                           46      46\n",
       "keisuke-tonkotsu-king                                   51      51\n",
       "komala-vilas-restaurant                                 55      55\n",
       "liao-fan-hong-kong-soya-sauce-chicken-rice-and-...      53      53\n",
       "long-beach-seafood                                      53      53\n",
       "no-signboard-seafood-restaurant                         50      50\n",
       "santouka                                                53      53\n",
       "sungei-road-laksa                                       55      55\n",
       "tolidos-espresso-nook                                   50      50"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby('Restaurant').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('train_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_urls_chn = {\n",
    "    \"bosses-restaurant\": \"https://www.yelp.com/biz/bosses-restaurant-singapore-2\",\n",
    "    \"taste-paradise\": \"https://www.yelp.com/biz/taste-paradise-singapore-3\",\n",
    "    \"jing-hua-restaurant-at-the-qun-zhong-eating-house\": \"https://www.yelp.com/biz/jing-hua-restaurant-at-the-qun-zhong-eating-house-singapore\",\n",
    "    \"imperial-treasure-super-peking-duck\": \"https://www.yelp.com/biz/imperial-treasure-super-peking-duck-singapore\",\n",
    "    \"crystal-jade-golden-palace\": \"https://www.yelp.com/biz/crystal-jade-golden-palace-singapore\"\n",
    "}\n",
    "\n",
    "test_urls_ind = {\n",
    "    \"the-curry-cultures\": \"https://www.yelp.com/biz/the-curry-cultures-no-title\",\n",
    "    \"zaffron-kitchen\": \"https://www.yelp.com/biz/zaffron-kitchen-singapore\",\n",
    "    \"the-song-of-india\": \"https://www.yelp.com/biz/the-song-of-india-singapore\",\n",
    "    \"tekka-market-and-food-centre\": \"https://www.yelp.com/biz/tekka-market-and-food-centre-singapore\",\n",
    "    \"samys-curry\": \"https://www.yelp.com/biz/samys-curry-singapore\"\n",
    "}\n",
    "\n",
    "test_urls_jpn = {\n",
    "    \"itacho-sushi\": \"https://www.yelp.com/biz/itacho-sushi-singapore-2\",\n",
    "    \"the-sushi-bar\": \"https://www.yelp.com/biz/the-sushi-bar-singapore\",\n",
    "    \"teppei\": \"https://www.yelp.com/biz/teppei-singapore\",\n",
    "    \"aoki\": \"https://www.yelp.com/biz/aoki-singapore\",\n",
    "    \"kinki\": \"https://www.yelp.com/biz/kinki-singapore\"\n",
    "}\n",
    "\n",
    "test_urls_frn = {\n",
    "    \"l-entrecote-bistro\": \"https://www.yelp.com/biz/l-entrecote-bistro-singapore\",\n",
    "    \"le-bistrot-du-sommelier\": \"https://www.yelp.com/biz/le-bistrot-du-sommelier-singapore\",\n",
    "    \"jaan\": \"https://www.yelp.com/biz/jaan-singapore\",\n",
    "    \"cocotte\": \"https://www.yelp.com/biz/cocotte-singapore\",\n",
    "    \"antoinette\": \"https://www.yelp.com/biz/antoinette-singapore-3\"\n",
    "}\n",
    "\n",
    "test_urls = {\"Chinese\": test_urls_chn, \"Indian\": test_urls_ind, \"Japanese\": test_urls_jpn, \"French\": test_urls_frn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(394, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = []\n",
    "ratings = []\n",
    "names = []\n",
    "cats = []\n",
    "\n",
    "for cat, d in test_urls.items():\n",
    "    for name, url in d.items():            \n",
    "        soup = make_soup(url)\n",
    "\n",
    "        for link in soup.find_all(\"div\", {\"class\": \"review-content\"}):\n",
    "            reviews.append(link.find('p').text)\n",
    "            ratings.append(link.find_all('img')[0].attrs['alt'])\n",
    "            names.append(name)\n",
    "            cats.append(cat)\n",
    "            \n",
    "df_test = pd.DataFrame({'Review': reviews, 'Rating': ratings, 'Restaurant': names, 'Category': cats})\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th>Restaurant</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Chinese</th>\n",
       "      <th>bosses-restaurant</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crystal-jade-golden-palace</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imperial-treasure-super-peking-duck</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jing-hua-restaurant-at-the-qun-zhong-eating-house</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taste-paradise</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">French</th>\n",
       "      <th>antoinette</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cocotte</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jaan</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l-entrecote-bistro</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>le-bistrot-du-sommelier</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Indian</th>\n",
       "      <th>samys-curry</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tekka-market-and-food-centre</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the-curry-cultures</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the-song-of-india</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zaffron-kitchen</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Japanese</th>\n",
       "      <th>aoki</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>itacho-sushi</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kinki</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>teppei</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the-sushi-bar</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            Review  Rating\n",
       "Category Restaurant                                                       \n",
       "Chinese  bosses-restaurant                                      20      20\n",
       "         crystal-jade-golden-palace                             17      17\n",
       "         imperial-treasure-super-peking-duck                    20      20\n",
       "         jing-hua-restaurant-at-the-qun-zhong-eating-house      20      20\n",
       "         taste-paradise                                         20      20\n",
       "French   antoinette                                             19      19\n",
       "         cocotte                                                20      20\n",
       "         jaan                                                   20      20\n",
       "         l-entrecote-bistro                                     20      20\n",
       "         le-bistrot-du-sommelier                                20      20\n",
       "Indian   samys-curry                                            20      20\n",
       "         tekka-market-and-food-centre                           20      20\n",
       "         the-curry-cultures                                     18      18\n",
       "         the-song-of-india                                      20      20\n",
       "         zaffron-kitchen                                        20      20\n",
       "Japanese aoki                                                   20      20\n",
       "         itacho-sushi                                           20      20\n",
       "         kinki                                                  20      20\n",
       "         teppei                                                 20      20\n",
       "         the-sushi-bar                                          20      20"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.groupby(['Category', 'Restaurant']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "\n",
    "train_set = pd.read_csv('train_data.csv')\n",
    "test_set = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define helper functions for text cleaning\n",
    "def removeIndent(phrase):\n",
    "    phrase = re.sub(\"\\n\", ' ', phrase)\n",
    "    phrase = re.sub(\"\\r\", ' ', phrase)\n",
    "    phrase = re.sub(\"\\t\", ' ', phrase)\n",
    "    return phrase\n",
    "\n",
    "def removePunc(phrase):\n",
    "    phrase = re.sub('&', ' and ', phrase)\n",
    "    phrase = re.sub(u\"\\\"\", \"\\'\", phrase)\n",
    "    phrase = re.sub(\"\\%\", \"percent\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean up review text\n",
    "train_rev = []\n",
    "test_rev = []\n",
    "\n",
    "for review in train_set[\"Review\"]:\n",
    "    sent_nostop = \" \".join(filter(lambda word: word not in stop, review.lower().split()))\n",
    "    sent_nostop = removePunc(removeIndent(sent_nostop))\n",
    "    train_rev.append(sent_nostop)\n",
    "    \n",
    "for review in test_set[\"Review\"]:\n",
    "    sent_nostop = \" \".join(filter(lambda word: word not in stop, review.lower().split()))\n",
    "    sent_nostop = removePunc(removeIndent(sent_nostop))\n",
    "    test_rev.append(sent_nostop)\n",
    "    \n",
    "train_set['Review_clean'] = train_rev\n",
    "test_set['Review_clean'] = test_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classify sentiment polarity\n",
    "train_sent = []\n",
    "test_sent = []\n",
    "\n",
    "pos_sent = ['4.0 star rating', '5.0 star rating']\n",
    "neg_sent = ['1.0 star rating', '2.0 star rating', '3.0 star rating']\n",
    "\n",
    "for rate in train_set['Rating']:\n",
    "    if rate in pos_sent:\n",
    "        train_sent.append(1)\n",
    "    elif rate in neg_sent:\n",
    "        train_sent.append(-1)\n",
    "    else:\n",
    "        print('Illegal rating found!')\n",
    "        \n",
    "for rate in test_set['Rating']:\n",
    "    if rate in pos_sent:\n",
    "        test_sent.append(1)\n",
    "    elif rate in neg_sent:\n",
    "        test_sent.append(-1)\n",
    "    else:\n",
    "        print('Illegal rating found!')\n",
    "\n",
    "train_set['Sentiment'] = train_sent\n",
    "test_set['Sentiment'] = test_sent       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Restaurant</th>\n",
       "      <th>Review_clean</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good place to have chili crabs. Second only to...</td>\n",
       "      <td>4.0 star rating</td>\n",
       "      <td>no-signboard-seafood-restaurant</td>\n",
       "      <td>good place chili crabs. second famous crab eat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It has been years since we were here and I rec...</td>\n",
       "      <td>1.0 star rating</td>\n",
       "      <td>no-signboard-seafood-restaurant</td>\n",
       "      <td>years since recall chili crab sauce rather dif...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Found this place on a list of best chili crab ...</td>\n",
       "      <td>2.0 star rating</td>\n",
       "      <td>no-signboard-seafood-restaurant</td>\n",
       "      <td>found place list best chili crab places singap...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This place is amazing!  In kind of a seedy are...</td>\n",
       "      <td>5.0 star rating</td>\n",
       "      <td>no-signboard-seafood-restaurant</td>\n",
       "      <td>place amazing! kind seedy area singapore baske...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>White pepper crab $80/kg. Kind of pricey as Ne...</td>\n",
       "      <td>3.0 star rating</td>\n",
       "      <td>no-signboard-seafood-restaurant</td>\n",
       "      <td>white pepper crab $80/kg. kind pricey newport ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sorry No Signboard, we really, really, really ...</td>\n",
       "      <td>2.0 star rating</td>\n",
       "      <td>no-signboard-seafood-restaurant</td>\n",
       "      <td>sorry signboard, really, really, really wanted...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>White pepper crab is really good and the quali...</td>\n",
       "      <td>5.0 star rating</td>\n",
       "      <td>no-signboard-seafood-restaurant</td>\n",
       "      <td>white pepper crab really good quality great co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>It's our first time in Singapore and we decide...</td>\n",
       "      <td>1.0 star rating</td>\n",
       "      <td>no-signboard-seafood-restaurant</td>\n",
       "      <td>first time singapore decided try seafood since...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>There are two No signboard restaurants and one...</td>\n",
       "      <td>4.0 star rating</td>\n",
       "      <td>no-signboard-seafood-restaurant</td>\n",
       "      <td>two signboard restaurants one open seating, up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The spicy crab is delicious and tasty. Come in...</td>\n",
       "      <td>4.0 star rating</td>\n",
       "      <td>no-signboard-seafood-restaurant</td>\n",
       "      <td>spicy crab delicious tasty. come afternoon din...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review           Rating  \\\n",
       "0  Good place to have chili crabs. Second only to...  4.0 star rating   \n",
       "1  It has been years since we were here and I rec...  1.0 star rating   \n",
       "2  Found this place on a list of best chili crab ...  2.0 star rating   \n",
       "3  This place is amazing!  In kind of a seedy are...  5.0 star rating   \n",
       "4  White pepper crab $80/kg. Kind of pricey as Ne...  3.0 star rating   \n",
       "5  Sorry No Signboard, we really, really, really ...  2.0 star rating   \n",
       "6  White pepper crab is really good and the quali...  5.0 star rating   \n",
       "7  It's our first time in Singapore and we decide...  1.0 star rating   \n",
       "8  There are two No signboard restaurants and one...  4.0 star rating   \n",
       "9  The spicy crab is delicious and tasty. Come in...  4.0 star rating   \n",
       "\n",
       "                        Restaurant  \\\n",
       "0  no-signboard-seafood-restaurant   \n",
       "1  no-signboard-seafood-restaurant   \n",
       "2  no-signboard-seafood-restaurant   \n",
       "3  no-signboard-seafood-restaurant   \n",
       "4  no-signboard-seafood-restaurant   \n",
       "5  no-signboard-seafood-restaurant   \n",
       "6  no-signboard-seafood-restaurant   \n",
       "7  no-signboard-seafood-restaurant   \n",
       "8  no-signboard-seafood-restaurant   \n",
       "9  no-signboard-seafood-restaurant   \n",
       "\n",
       "                                        Review_clean  Sentiment  \n",
       "0  good place chili crabs. second famous crab eat...          1  \n",
       "1  years since recall chili crab sauce rather dif...         -1  \n",
       "2  found place list best chili crab places singap...         -1  \n",
       "3  place amazing! kind seedy area singapore baske...          1  \n",
       "4  white pepper crab $80/kg. kind pricey newport ...         -1  \n",
       "5  sorry signboard, really, really, really wanted...         -1  \n",
       "6  white pepper crab really good quality great co...          1  \n",
       "7  first time singapore decided try seafood since...         -1  \n",
       "8  two signboard restaurants one open seating, up...          1  \n",
       "9  spicy crab delicious tasty. come afternoon din...          1  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Restaurant</th>\n",
       "      <th>Review_clean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>465</td>\n",
       "      <td>465</td>\n",
       "      <td>465</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Review  Rating  Restaurant  Review_clean\n",
       "Sentiment                                          \n",
       "-1            159     159         159           159\n",
       " 1            465     465         465           465"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.groupby('Sentiment').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Restaurant</th>\n",
       "      <th>Category</th>\n",
       "      <th>Review_clean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>282</td>\n",
       "      <td>282</td>\n",
       "      <td>282</td>\n",
       "      <td>282</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Review  Rating  Restaurant  Category  Review_clean\n",
       "Sentiment                                                    \n",
       "-1            112     112         112       112           112\n",
       " 1            282     282         282       282           282"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.groupby('Sentiment').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build predictive models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize as wt\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrangle data in required format for model building\n",
    "train_pos = [[row[\"Review_clean\"], 1] for idx, row in train_set.iterrows() if row[\"Sentiment\"] == 1]\n",
    "train_neg = [[row[\"Review_clean\"], -1] for idx, row in train_set.iterrows() if row[\"Sentiment\"] == -1]\n",
    "\n",
    "train_list = train_pos + train_neg\n",
    "train_tokenized = [[wt(rev), lab] for rev, lab in train_list]\n",
    "\n",
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])\n",
    "\n",
    "train_featureset = [(word_feats(words), lab) for (words, lab) in train_tokenized] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "624"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_featureset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load standard train set\n",
    "ffile1 = open(\"train.csv\", \"r\", encoding = \"ISO-8859-1\")\n",
    "df = pd.read_csv(ffile1, encoding = \"utf-8\")\n",
    "ffile1.close()\n",
    "\n",
    "train_rev_std = []\n",
    "\n",
    "for review in df[\"text\"]:\n",
    "    sent_nostop = \" \".join(filter(lambda word: word not in stop, review.lower().split()))\n",
    "    sent_nostop = removePunc(removeIndent(sent_nostop))\n",
    "    train_rev_std.append(sent_nostop)\n",
    "    \n",
    "df['text_clean'] = train_rev_std\n",
    "\n",
    "train_pos_std = [[row[\"text_clean\"], 1] for idx, row in df.iterrows() if row[\"Sentiment\"] == \"positive\"]\n",
    "train_neg_std = [[row[\"text_clean\"], -1] for idx, row in df.iterrows() if row[\"Sentiment\"] == \"negative\"]\n",
    "\n",
    "train_list_std = train_pos_std + train_neg_std\n",
    "train_tokenized_std = [[wt(rev), lab] for rev, lab in train_list_std]\n",
    "train_featureset_std = [(word_feats(words), lab) for (words, lab) in train_tokenized_std] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20329"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_featureset_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Augment train datasets into one\n",
    "train_featureset_all = train_featureset + train_featureset_std\n",
    "train_list_all = train_list + train_list_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20953"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_featureset_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "              flavorless = True               -1 : 1      =     40.4 : 1.0\n",
      "            unacceptable = True               -1 : 1      =     34.2 : 1.0\n",
      "                  rudely = True               -1 : 1      =     30.1 : 1.0\n",
      "                  brazil = True               -1 : 1      =     27.7 : 1.0\n",
      "               redeeming = True               -1 : 1      =     26.0 : 1.0\n",
      "               poisoning = True               -1 : 1      =     25.0 : 1.0\n",
      "              microwaved = True               -1 : 1      =     24.8 : 1.0\n",
      "               disgusted = True               -1 : 1      =     24.8 : 1.0\n",
      "                   worst = True               -1 : 1      =     23.8 : 1.0\n",
      "              disgusting = True               -1 : 1      =     23.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes Rule using nltk\n",
    "classifier_nb = NaiveBayesClassifier.train(train_featureset_all)\n",
    "classifier_nb.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred        -1     1    All\n",
      "actuals                    \n",
      "-1       10382   788  11170\n",
      "1         1471  8312   9783\n",
      "All      11853  9100  20953\n",
      "\n",
      "\n",
      "Accuracy: 0.892\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.93      0.88      0.90     11853\n",
      "          1       0.85      0.91      0.88      9100\n",
      "\n",
      "avg / total       0.89      0.89      0.89     20953\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_txt = [t[0] for t in train_list_all]\n",
    "train_lab = [t[1] for t in train_list_all]\n",
    "\n",
    "#Create tf-idf matrix\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_vectors = vectorizer.fit_transform(train_txt)\n",
    "\n",
    "#Train Naive Bayes Rule using sklearn\n",
    "clf = MultinomialNB().fit(train_vectors, train_lab)\n",
    "\n",
    "predNB_train = clf.predict(train_vectors)\n",
    "cm = pd.crosstab(pd.Series(train_lab), pd.Series(predNB_train), rownames=['actuals'], colnames=['pred'], margins=True)\n",
    "print(cm)\n",
    "print('\\n')\n",
    "print('Accuracy: ' + str(round(accuracy_score(predNB_train, train_lab), 3)))\n",
    "print('\\n')\n",
    "print(classification_report(predNB_train, train_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrangle test data for prediction\n",
    "test_pos = [[row[\"Review_clean\"], 1] for idx, row in test_set.iterrows() if row[\"Sentiment\"] == 1]\n",
    "test_neg = [[row[\"Review_clean\"], -1] for idx, row in test_set.iterrows() if row[\"Sentiment\"] == -1]\n",
    "test_list = test_pos + test_neg\n",
    "\n",
    "test_txt = [t[0] for t in test_list]\n",
    "test_lab = [t[1] for t in test_list]\n",
    "test_vectors = vectorizer.transform(test_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred      -1    1  All\n",
      "actuals               \n",
      "-1        91   21  112\n",
      "1         54  228  282\n",
      "All      145  249  394\n",
      "\n",
      "\n",
      "Accuracy: 0.81\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.81      0.63      0.71       145\n",
      "          1       0.81      0.92      0.86       249\n",
      "\n",
      "avg / total       0.81      0.81      0.80       394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict on test data\n",
    "predNB_test = clf.predict(test_vectors)\n",
    "cm = pd.crosstab(pd.Series(test_lab), pd.Series(predNB_test), rownames=['actuals'], colnames=['pred'], margins=True)\n",
    "print(cm)\n",
    "print('\\n')\n",
    "print('Accuracy: ' + str(round(accuracy_score(predNB_test, test_lab), 3)))\n",
    "print('\\n')\n",
    "print(classification_report(predNB_test, test_lab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred      -1    1  All\n",
      "actuals               \n",
      "-1        91   21  112\n",
      "1         44  238  282\n",
      "All      135  259  394\n",
      "\n",
      "\n",
      "Accuracy: 0.835\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.81      0.67      0.74       135\n",
      "          1       0.84      0.92      0.88       259\n",
      "\n",
      "avg / total       0.83      0.84      0.83       394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SVM Classifier from sklearn\n",
    "def train_svm(X, y):\n",
    "    \"\"\"\n",
    "    Create and train the Support Vector Machine.\n",
    "    \"\"\"\n",
    "    svm = SVC(C=10000.0, gamma='auto', kernel='rbf')\n",
    "    svm.fit(X, y)\n",
    "    return svm\n",
    "\n",
    "clf_svm = train_svm(train_vectors, train_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred        -1     1    All\n",
      "actuals                    \n",
      "-1       10349   821  11170\n",
      "1          687  9096   9783\n",
      "All      11036  9917  20953\n",
      "\n",
      "\n",
      "Accuracy: 0.928\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.93      0.94      0.93     11036\n",
      "          1       0.93      0.92      0.92      9917\n",
      "\n",
      "avg / total       0.93      0.93      0.93     20953\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#In-sample prediction\n",
    "predSVM_train = clf_svm.predict(train_vectors)\n",
    "cm = pd.crosstab(pd.Series(train_lab), pd.Series(predSVM_train), rownames=['actuals'], colnames=['pred'], margins=True)\n",
    "print(cm)\n",
    "print('\\n')\n",
    "print('Accuracy: ' + str(round(accuracy_score(predSVM_train, train_lab), 3)))\n",
    "print('\\n')\n",
    "print(classification_report(predSVM_train, train_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred      -1    1  All\n",
      "actuals               \n",
      "-1        91   21  112\n",
      "1         44  238  282\n",
      "All      135  259  394\n",
      "\n",
      "\n",
      "Accuracy: 0.835\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.81      0.67      0.74       135\n",
      "          1       0.84      0.92      0.88       259\n",
      "\n",
      "avg / total       0.83      0.84      0.83       394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Out-sample prediction\n",
    "predSVM_test = clf_svm.predict(test_vectors)\n",
    "cm = pd.crosstab(pd.Series(test_lab), pd.Series(predSVM_test), rownames=['actuals'], colnames=['pred'], margins=True)\n",
    "print(cm)\n",
    "print('\\n')\n",
    "print('Accuracy: ' + str(round(accuracy_score(predSVM_test, test_lab), 3)))\n",
    "print('\\n')\n",
    "print(classification_report(predSVM_test, test_lab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering by negation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define negation helper function\n",
    "def neg_tag(text):\n",
    "    transformed = re.sub(r\"\\b(?:never|nothing|nowhere|noone|none|not|haven't|hasn't|hasnt|hadn't|hadnt|can't|cant|couldn't|couldnt|shouldn't|shouldnt|won't|wont|wouldn't|wouldnt|don't|dont|doesn't|doesnt|didn't|didnt|isnt|isn't|aren't|arent|aint|ain't|hardly|seldom)\\b[\\w\\s]+[^\\w\\s]\", lambda match: re.sub(r'(\\s+)(\\w+)', r'\\1NEG_\\2', match.group(0)), text, flags=re.IGNORECASE)\n",
    "    return(transformed)\n",
    "\n",
    "train_list_neg = []\n",
    "\n",
    "for doc in train_list_all:\n",
    "    trans = neg_tag(doc[0])\n",
    "    lab = doc[1]\n",
    "    train_list_neg.append([trans, lab])\n",
    "    \n",
    "test_list_neg = []\n",
    "\n",
    "for doc in test_list:\n",
    "    trans = neg_tag(doc[0])\n",
    "    lab = doc[1]\n",
    "    test_list_neg.append([trans, lab])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rebuild Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "              flavorless = True               -1 : 1      =     39.8 : 1.0\n",
      "            unacceptable = True               -1 : 1      =     34.2 : 1.0\n",
      "                  rudely = True               -1 : 1      =     29.5 : 1.0\n",
      "                  brazil = True               -1 : 1      =     27.7 : 1.0\n",
      "               redeeming = True               -1 : 1      =     24.8 : 1.0\n",
      "               poisoning = True               -1 : 1      =     24.3 : 1.0\n",
      "              microwaved = True               -1 : 1      =     24.2 : 1.0\n",
      "               disgusted = True               -1 : 1      =     24.2 : 1.0\n",
      "                   worst = True               -1 : 1      =     23.7 : 1.0\n",
      "                   stale = True               -1 : 1      =     23.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "train_tokenized_neg = [[wt(rev), lab] for rev, lab in train_list_neg]\n",
    "train_featureset_neg = [(word_feats(words), lab) for (words, lab) in train_tokenized_neg]\n",
    "\n",
    "#Naive Bayes Rule using nltk\n",
    "classifier_nb_neg = NaiveBayesClassifier.train(train_featureset_neg)\n",
    "classifier_nb_neg.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No negation feature appearing in most informative features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred        -1     1    All\n",
      "actuals                    \n",
      "-1       10413   757  11170\n",
      "1         1421  8362   9783\n",
      "All      11834  9119  20953\n",
      "\n",
      "\n",
      "Accuracy: 0.896\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.93      0.88      0.91     11834\n",
      "          1       0.85      0.92      0.88      9119\n",
      "\n",
      "avg / total       0.90      0.90      0.90     20953\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_txt_neg = [t[0] for t in train_list_neg]\n",
    "train_lab_neg = [t[1] for t in train_list_neg]\n",
    "\n",
    "vectorizer_neg = TfidfVectorizer()\n",
    "train_vectors_neg = vectorizer_neg.fit_transform(train_txt_neg)\n",
    "\n",
    "#Train Naive Bayes Rule using sklearn\n",
    "clf_neg = MultinomialNB().fit(train_vectors_neg, train_lab_neg)\n",
    "\n",
    "predNB_train_neg = clf_neg.predict(train_vectors_neg)\n",
    "cm = pd.crosstab(pd.Series(train_lab_neg), pd.Series(predNB_train_neg), rownames=['actuals'], colnames=['pred'], margins=True)\n",
    "print(cm)\n",
    "print('\\n')\n",
    "print('Accuracy: ' + str(round(accuracy_score(predNB_train_neg, train_lab_neg), 3)))\n",
    "print('\\n')\n",
    "print(classification_report(predNB_train_neg, train_lab_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In-sample prediction overall accuracy is slightly higher than modelling without negation features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_txt_neg = [t[0] for t in test_list_neg]\n",
    "test_lab_neg = [t[1] for t in test_list_neg]\n",
    "test_vectors_neg = vectorizer_neg.transform(test_txt_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred      -1    1  All\n",
      "actuals               \n",
      "-1        92   20  112\n",
      "1         59  223  282\n",
      "All      151  243  394\n",
      "\n",
      "\n",
      "Accuracy: 0.799\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.82      0.61      0.70       151\n",
      "          1       0.79      0.92      0.85       243\n",
      "\n",
      "avg / total       0.80      0.80      0.79       394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict on test data\n",
    "predNB_test_neg = clf_neg.predict(test_vectors_neg)\n",
    "cm = pd.crosstab(pd.Series(test_lab_neg), pd.Series(predNB_test_neg), rownames=['actuals'], colnames=['pred'], margins=True)\n",
    "print(cm)\n",
    "print('\\n')\n",
    "print('Accuracy: ' + str(round(accuracy_score(predNB_test_neg, test_lab_neg), 3)))\n",
    "print('\\n')\n",
    "print(classification_report(predNB_test_neg, test_lab_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out-sample prediction overall accuracy dropped comparing to the model without negation features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rebuild SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred      -1    1  All\n",
      "actuals               \n",
      "-1        91   21  112\n",
      "1         43  239  282\n",
      "All      134  260  394\n",
      "\n",
      "\n",
      "Accuracy: 0.838\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.81      0.68      0.74       134\n",
      "          1       0.85      0.92      0.88       260\n",
      "\n",
      "avg / total       0.84      0.84      0.83       394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SVM Classifier from sklearn\n",
    "clf_svm_neg = train_svm(train_vectors_neg, train_lab_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred        -1     1    All\n",
      "actuals                    \n",
      "-1       10363   807  11170\n",
      "1          707  9076   9783\n",
      "All      11070  9883  20953\n",
      "\n",
      "\n",
      "Accuracy: 0.928\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.93      0.94      0.93     11070\n",
      "          1       0.93      0.92      0.92      9883\n",
      "\n",
      "avg / total       0.93      0.93      0.93     20953\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#In-sample prediction\n",
    "predSVM_train_neg = clf_svm_neg.predict(train_vectors_neg)\n",
    "cm = pd.crosstab(pd.Series(train_lab_neg), pd.Series(predSVM_train_neg), rownames=['actuals'], colnames=['pred'], margins=True)\n",
    "print(cm)\n",
    "print('\\n')\n",
    "print('Accuracy: ' + str(round(accuracy_score(predSVM_train_neg, train_lab_neg), 3)))\n",
    "print('\\n')\n",
    "print(classification_report(predSVM_train_neg, train_lab_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No change for in-sample prediction overall accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred      -1    1  All\n",
      "actuals               \n",
      "-1        91   21  112\n",
      "1         43  239  282\n",
      "All      134  260  394\n",
      "\n",
      "\n",
      "Accuracy: 0.838\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.81      0.68      0.74       134\n",
      "          1       0.85      0.92      0.88       260\n",
      "\n",
      "avg / total       0.84      0.84      0.83       394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Out-sample prediction\n",
    "predSVM_test_neg = clf_svm_neg.predict(test_vectors_neg)\n",
    "cm = pd.crosstab(pd.Series(test_lab_neg), pd.Series(predSVM_test_neg), rownames=['actuals'], colnames=['pred'], margins=True)\n",
    "print(cm)\n",
    "print('\\n')\n",
    "print('Accuracy: ' + str(round(accuracy_score(predSVM_test_neg, test_lab_neg), 3)))\n",
    "print('\\n')\n",
    "print(classification_report(predSVM_test_neg, test_lab_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM model out-sample overall accuracy improved only slightly through using negation features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making output files in required format\n",
    "#Take best performing model (SVM with negation) for prediction score\n",
    "train_pos_raw = [row[\"Review\"] for idx, row in train_set.iterrows() if row[\"Sentiment\"] == 1]\n",
    "train_neg_raw = [row[\"Review\"] for idx, row in train_set.iterrows() if row[\"Sentiment\"] == -1]\n",
    "train_list_raw = train_pos_raw + train_neg_raw\n",
    "\n",
    "train_pos_std_raw = [row[\"text\"] for idx, row in df.iterrows() if row[\"Sentiment\"] == \"positive\"]\n",
    "train_neg_std_raw = [row[\"text\"] for idx, row in df.iterrows() if row[\"Sentiment\"] == \"negative\"]\n",
    "train_list_std_raw = train_pos_std_raw + train_neg_std_raw\n",
    "\n",
    "train_list_all_raw = train_list_raw + train_list_std_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'text': train_list_all_raw, 'score': predSVM_train_neg}).to_csv('train_scored.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pos_raw = [row[\"Review\"] for idx, row in test_set.iterrows() if row[\"Sentiment\"] == 1]\n",
    "test_neg_raw = [row[\"Review\"] for idx, row in test_set.iterrows() if row[\"Sentiment\"] == -1]\n",
    "test_list_raw = test_pos_raw + test_neg_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_pred = pd.DataFrame({'text': test_list_raw, 'score': predSVM_test_neg})\n",
    "test_set_pred.to_csv('test_scored.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append prediction to original test dataframe\n",
    "pred_list = []\n",
    "\n",
    "for idx, row in test_set.iterrows():\n",
    "    for idx2, row2 in test_set_pred.iterrows():\n",
    "        if row['Review'] == row2['text']:\n",
    "            pred_list.append(row2['score'])\n",
    "            \n",
    "test_set['pred'] = pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode into json file\n",
    "#test_urls = {\"Chinese\": test_urls_chn, \"Indian\": test_urls_ind, \"Japanese\": test_urls_jpn, \"French\": test_urls_frn}\n",
    "dict_cat = {}\n",
    "\n",
    "for cat, urls in test_urls.items():    \n",
    "    name_list = []\n",
    "    \n",
    "    for name in urls.keys():        \n",
    "        review_list = [{'text': row[\"Review\"], 'score': row[\"pred\"]} for idx, row in test_set.iterrows() if row[\"Restaurant\"] == name]        \n",
    "        name_dict = {\"name\": name, \"nb_review\": len(review_list), \"reviews\": review_list}\n",
    "        name_list.append(name_dict)\n",
    "        \n",
    "    dict_cat.update({cat: name_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('Day2_Group14.json', 'w') as outfile:\n",
    "    json.dump(dict_cat, outfile, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
